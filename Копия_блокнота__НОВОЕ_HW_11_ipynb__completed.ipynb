{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTXF9oHWmB7"
      },
      "source": [
        "# Домашнее задание 11\n",
        "\n",
        "\n",
        "В этом задании вам предстоит построить архитектуру автоэнкодера, который будет сжимать и восстанавливать лица людей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asnhHgjSACuz"
      },
      "source": [
        "## Задание: Создание модели Vanilla AE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoLIyu9-6I78"
      },
      "source": [
        "Ваша задача — реализовать класс атоэнкодера для данных.\n",
        "\n",
        "Обратите внимание на то, сколько карт активации должно быть в последнем слое сети.\n",
        "\n",
        "\n",
        "Вы можете варьировать количества блоков/слоев и устройства блоков. Архитектура блока (conv -> batch norm-> relu -> maxpool) подойдет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJrda_0eMU9R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def encoder_block(in_channels, out_channels, kernel_size=3, padding=1):\n",
        "    \"\"\"\n",
        "    Encoder block:\n",
        "    Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU -> MaxPool\n",
        "    Reduces spatial resolution by 2 while increasing channels.\n",
        "    \"\"\"\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "def decoder_block(in_channels, out_channels, kernel_size=3, padding=1):\n",
        "    \"\"\"\n",
        "    Decoder block:\n",
        "    TransposedConv (upsample) -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU\n",
        "    Doubles spatial resolution while reducing channels.\n",
        "    \"\"\"\n",
        "    block = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder: 64x64 -> 32x32 -> 16x16 -> 8x8\n",
        "        self.encoder = nn.Sequential(\n",
        "            encoder_block(3, 64),      # -> (64, 32, 32)\n",
        "            encoder_block(64, 128),    # -> (128, 16, 16)\n",
        "            encoder_block(128, 256)    # -> (256, 8, 8)\n",
        "        )\n",
        "\n",
        "        # Decoder: 8x8 -> 16x16 -> 32x32 -> 64x64\n",
        "        self.decoder = nn.Sequential(\n",
        "            decoder_block(256, 128),   # -> (128, 16, 16)\n",
        "            decoder_block(128, 64),    # -> (64, 32, 32)\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2),  # -> (3, 64, 64)\n",
        "            nn.Sigmoid()  # keep outputs in [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)       # downsampling\n",
        "        reconstruction = self.decoder(latent)  # upsampling\n",
        "        return reconstruction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6-LSkda5IGr"
      },
      "source": [
        "Ячейка ниже проверяет, что модель работает правильно:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezQXjpkb5FB3"
      },
      "outputs": [],
      "source": [
        "# проверка, что у модели есть обучаемые слои\n",
        "model = Autoencoder()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "assert num_params > 10\n",
        "\n",
        "# проверка, что модель собрана верно\n",
        "random_tensor = torch.Tensor(np.random.random((32, 3, 64, 64)))\n",
        "model = Autoencoder()\n",
        "out = model(random_tensor)\n",
        "assert out.shape == (32, 3, 64, 64), \"неверный размер выхода модели\"\n",
        "\n",
        "# проверка, что у модели можно отцепить декодер и использовать его как\n",
        "# отдельную модель\n",
        "# если здесь возникла ошибка, убедитесь, что в вашей сети нет skip connection\n",
        "random_tensor = torch.Tensor(np.random.random((32, 3, 64, 64)))\n",
        "model = Autoencoder()\n",
        "latent_shape = model.encoder(random_tensor).shape\n",
        "latent = torch.Tensor(np.random.random(latent_shape))\n",
        "out = model.decoder(latent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc5906xi7bIh"
      },
      "source": [
        "### Сдача задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQZGIemr7eD0"
      },
      "source": [
        "Если обе ячейки отработали без ошибок, можно сдавать задание в первую задачу на Я.Контесте. Для этого нужно скопировать класс Autoencoder в нужное место в submission_template10.py и отправить submission_template10.py в Я.Контест."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}